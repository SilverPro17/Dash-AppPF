{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados (EDA) - Temperatura da Superfície do Mar (SST)\n",
    "\n",
    "Este notebook realiza a análise exploratória inicial do dataset NOAA OI SST V2 High Resolution.\n",
    "\n",
    "**Dataset:** `sst.mon.mean.nc`\n",
    "**Fonte:** NOAA PSL THREDDS Server\n",
    "\n",
    "**Nota:** Devido ao tamanho do dataset (~2GB), algumas operações (como o cálculo da média global) podem consumir muita memória. Esta versão utiliza `chunks` para carregar os dados de forma mais eficiente e calcula a média global sobre um subconjunto temporal para evitar problemas de memória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "# Definir diretório base do projeto\n",
    "project_dir = \"/home/ubuntu/plankton_project\"\n",
    "report_dir = os.path.join(project_dir, \"report\")\n",
    "data_dir = os.path.join(project_dir, \"data\")\n",
    "\n",
    "# Criar diretório de report se não existir\n",
    "os.makedirs(report_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Diretório de report: {report_dir}\")\n",
    "print(\"Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar o Dataset com Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o ficheiro NetCDF\n",
    "sst_file_path = os.path.join(data_dir, \"sst.mon.mean.nc\")\n",
    "\n",
    "# Carregar o dataset usando xarray com chunks para otimizar memória\n",
    "# Ajustar o tamanho dos chunks conforme necessário\n",
    "try:\n",
    "    ds_sst = xr.open_dataset(sst_file_path, chunks={\"time\": 12}) # Chunks de 12 meses (1 ano)\n",
    "    print(f\"Dataset SST carregado com sucesso de {sst_file_path} usando chunks.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Ficheiro não encontrado em {sst_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o dataset: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspeção Inicial do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir a estrutura do dataset\n",
    "if 'ds_sst' in locals() and ds_sst is not None:\n",
    "    print(\"Estrutura do Dataset SST:\")\n",
    "    print(ds_sst)\n",
    "else:\n",
    "    print(\"Dataset não foi carregado corretamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar as variáveis disponíveis\n",
    "if 'ds_sst' in locals() and ds_sst is not None:\n",
    "    print(\"\\nVariáveis:\")\n",
    "    for var in ds_sst.data_vars:\n",
    "        print(f\"- {var}: {ds_sst[var].attrs.get('long_name', 'N/A')}\")\n",
    "\n",
    "    print(\"\\nCoordenadas:\")\n",
    "    for coord in ds_sst.coords:\n",
    "        print(f\"- {coord}\")\n",
    "\n",
    "    print(\"\\nAtributos Globais:\")\n",
    "    print(ds_sst.attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise Preliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ds_sst' in locals() and ds_sst is not None:\n",
    "    # Cobertura Temporal\n",
    "    time_min = ds_sst['time'].min().values\n",
    "    time_max = ds_sst['time'].max().values\n",
    "    print(f\"Cobertura Temporal: {np.datetime_as_string(time_min, unit='D')} a {np.datetime_as_string(time_max, unit='D')}\")\n",
    "\n",
    "    # Cobertura Espacial\n",
    "    lat_min, lat_max = ds_sst['lat'].min().values, ds_sst['lat'].max().values\n",
    "    lon_min, lon_max = ds_sst['lon'].min().values, ds_sst['lon'].max().values\n",
    "    print(f\"Cobertura Espacial (Lat): {lat_min}° a {lat_max}°\")\n",
    "    print(f\"Cobertura Espacial (Lon): {lon_min}° a {lon_max}°\")\n",
    "\n",
    "    # Verificar unidades da variável SST\n",
    "    sst_units = ds_sst['sst'].attrs.get('units', 'N/A')\n",
    "    print(f\"Unidades de SST: {sst_units}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualização Inicial (com Otimização de Memória)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ds_sst' in locals() and ds_sst is not None:\n",
    "    # Selecionar um subconjunto temporal (ex: últimos 5 anos) para calcular a média global\n",
    "    try:\n",
    "        latest_time = ds_sst['time'].max()\n",
    "        start_date_subset = latest_time - np.timedelta64(5*365, 'D') # Aproximadamente 5 anos atrás\n",
    "        sst_subset = ds_sst['sst'].sel(time=slice(start_date_subset, latest_time))\n",
    "\n",
    "        print(\"Calculando a média temporal para os últimos 5 anos...\")\n",
    "        sst_mean_subset = sst_subset.mean(dim='time').compute()\n",
    "        print(\"Cálculo da média concluído.\")\n",
    "\n",
    "        # Plotar o mapa da SST média (subconjunto)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sst_mean_subset.plot(cmap='viridis')\n",
    "        plt.title(f'Temperatura Média Global da Superfície do Mar (SST) - Média Mensal (Últimos 5 anos)')\n",
    "        plt.xlabel('Longitude')\n",
    "        plt.ylabel('Latitude')\n",
    "        plt.tight_layout()\n",
    "        # Salvar a figura com caminho absoluto\n",
    "        save_path_map = os.path.join(report_dir, 'sst_mean_subset_map.png')\n",
    "        plt.savefig(save_path_map)\n",
    "        print(f\"Mapa da SST média (subconjunto) salvo em {save_path_map}\")\n",
    "        plt.close() # Fechar a figura para libertar memória\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao calcular ou plotar a média do subconjunto: {e}\")"
   ]
  },
    {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ds_sst' in locals() and ds_sst is not None:\n",
    "    # Selecionar um ponto para a série temporal (ex: próximo ao Equador no Atlântico)\n",
    "    lat_point = 0\n",
    "    lon_point = 330 # Equivalente a -30 Oeste\n",
    "\n",
    "    try:\n",
    "        print(f\"Extraindo série temporal para o ponto ({lat_point}°, {lon_point-360}°W)...\")\n",
    "        sst_timeseries = ds_sst['sst'].sel(lat=lat_point, lon=lon_point, method='nearest').compute()\n",
    "        print(\"Extração da série temporal concluída.\")\n",
    "\n",
    "        # Plotar a série temporal\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        sst_timeseries.plot()\n",
    "        plt.title(f'Série Temporal da SST Mensal no Ponto ({lat_point}°, {lon_point-360}°W)')\n",
    "        plt.xlabel('Data')\n",
    "        plt.ylabel(f'SST ({sst_units})')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        # Salvar a figura com caminho absoluto\n",
    "        save_path_ts = os.path.join(report_dir, 'sst_timeseries_point.png')\n",
    "        plt.savefig(save_path_ts)\n",
    "        print(f\"Série temporal da SST salva em {save_path_ts}\")\n",
    "        plt.close() # Fechar a figura para libertar memória\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao extrair ou plotar a série temporal: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Próximos Passos\n",
    "\n",
    "- Análise mais detalhada das distribuições.\n",
    "- Tratamento de valores ausentes.\n",
    "- Cálculo de anomalias.\n",
    "- Exploração de padrões sazonais e tendências.\n",
    "- Download e EDA do dataset de Clorofila-a.\n",
    "- Processamento e EDA do dataset de Plâncton."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

